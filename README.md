# mlops_pracs
## Module 1
<details>

* Необходимо из создать простейший конвейер для автоматизации работы с моделью машинного обучения. 
* Отдельные этапы конвейера машинного обучения описываются в разных python–скриптах, которые потом соединяются в единую цепочку действий с помощью bash-скрипта.
* Все файлы необходимо разместить в подкаталоге lab1 корневого каталога

Этапы:
1. Создайте python-скрипт (data_creation.py), который создает различные наборы данных, описывающие некий процесс (например, изменение дневной температуры). Таких наборов должно быть несколько, в некоторые данные можно включить аномалии или шумы. 
Часть наборов данных должны быть сохранены в папке “train”, другая часть в папке “test”. Одним из вариантов выполнения этого этапа может быть скачивание набора данных из сети, и разделение выборки на тестовую и обучающую. Учтите, что файл должен быть доступен и методы скачивания либо есть в ubuntu либо устанавливаются через pip в файле pipeline.sh
2. Создайте python-скрипт (data_preprocessing.py), который выполняет предобработку данных, например, с помощью sklearn.preprocessing.StandardScaler. Трансформации выполняются и над тестовой и над обучающей выборкой. 
3. Создайте python-скрипт (model_preparation.py), который создает и обучает модель машинного обучения на построенных данных из папки “train”. Для сохранения модели в файл можно воспользоваться [pickle](https://docs.python.org/3/library/pickle.html) (см. [пример](https://rukovodstvo.net/posts/id_1322/))
4. Создайте python-скрипт (model_testing.py), проверяющий модель машинного обучения на построенных данных из папки “test”.
5. Напишите bash-скрипт (pipeline.sh), последовательно запускающий все python-скрипты. При необходимости усложните скрипт. В результате выполнения скрипта на терминал в стандартный поток вывода печатается одна строка с оценкой метрики на вашей модели, например:
</details>

## Module 2
<details>
* Дженкинс файл лежит в папке lab1

* Вам нужно разработать собственный конвейер автоматизации для проекта машинного обучения. Для этого вам понадобится виртуальная машина с установленным Jenkins, python и   
* необходимыми библиотеками. В ходе выполнения практического задания вам необходимо автоматизировать сбор данных, подготовку датасета, обучение модели и работу модели. 

 

Этапы задания 

Развернуть сервер с Jenkins, установить необходимое программное обеспечение для работы над созданием модели машинного обучения. 
Выбрать способ получения данных (скачать из github, из Интернета, wget, SQL запрос, …). 
Провести обработку данных, выделить важные признаки, сформировать датасеты для тренировки и тестирования модели, сохранить. 
Создать и обучить на тренировочном датасете модель машинного обучения, сохранить в pickle или аналогичном формате. 
Загрузить сохраненную модель на ​предыдущем этапе и проанализировать ее качество на тестовых данных.

## Module 3
<details>
3. Контейнеризация
Срок заканчивается 2 апреля 2024 г., 23:59
Инструкции
В практическом задание по модулю вам необходимо применить полученные знания по работе с docker (и docker-compose). Вам необходимо использовать полученные ранее знания по созданию микросервисов. В этом задании необходимо развернуть микросервис в контейнере докер. Например, это может быть модель машинного обучения, принимающая запрос по API и возвращающая ответ. Вариантом может быть реализация приложения на основе streamlit (https://github.com/korelin/streamlit_demo_app). 

Результаты работы над этой работой стоит поместить в подкаталог lab3 вашего корневого каталога репозитория.

Что необходимо выполнить:

Подготовить python код для модели и микросервиса

Создать Docker file

Создать docker образ

Запустить docker контейнер и проверить его работу



*Дополнительно будут оцениваться:

Использование docker-compose
Автоматизация сборки образа привязка имени тэга к версии сборки (sha-коммита, имя ветки)

Деплой (загрузка) образа в хранилище артефактов например dockerhub

## Module 4
<details>
4. Управление даными
Срок заканчивается сегодня в 23:59
Инструкции
В практическом задании данного модуля вам необходимо продемонстрировать навыки практического использования утилиты dvc для работы с данными. В результате выполнения этих заданий вы выполните все основные операции с dvc и закрепите полученные теоретические знания практическими действиями. 

 

Этапы задания: 

Установите git и dvc. 
Создайте папку lab4 в корне проекта. 
Настройте папку проекта для работы с git и dvc. 
Настройте git репозиторий. 
Настройте удаленное хранилище файлов, например на Google Disk или S3. 
Создайте датасет о пассажирах “Титаника”, например, catboost.titanic(). 
Создайте датасет, в котором содержится информация о классе (“Pclass”),  поле (“Sex”) и возрасте (“Age”) пассажира. Сделайте коммит в git и push в dvc. 
Создайте новую версию датасета, в котором пропущенные (nan) значения в поле “Age” будут заполнены средним значением. Сделайте коммит в git и push в dvc. 
Создайте новый признак с использованием one-hot-encoding для строкового признака “Пол” (“Sex”). Сделайте коммит в git и push в dvc. 
Выполните переключение между всеми созданными версиями датасета. 
При правильном выполнении задания и вас появится git репозиторий с опубликованной метаинформацией и папка на Google Disk, в которой хранятся различные версии датасетов. 

 

В постановке задачи используется датасет из конкурса “Titanic Disaster”, однако вы можете использовать свои наборы данных, в этом случае в п.п.6-9 необходимо использовать информацию и признаки из вашего датасета. 
